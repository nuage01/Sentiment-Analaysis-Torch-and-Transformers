{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Importing Wheights and Vocabulary</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
    "project_id = 'dataimpact-rd'\n",
    "!gcloud config set project {project_id}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://di_data_sas/Sentiment_Analysis_Related_Data/EN/weights_model_topics.h5  topics.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://di_data_sas/Sentiment_Analysis_Related_Data/EN/vocab.model vocab.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://di_data_sas/Sentiment_Analysis_Related_Data/EN/weights_model_score.h5 score.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Importing the model</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import gensim, nltk, re\n",
    "\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Bidirectional, Conv1D, CuDNNLSTM, Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.python.keras.layers import normalization, Input, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_tokenizer(line):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(line)\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "def encode_docs(tokenizer, max_length, docs):\n",
    "\n",
    "    encoded = tokenizer.texts_to_sequences(docs)\n",
    "    padded = pad_sequences(encoded, maxlen = max_length, padding = 'post')\n",
    "    \n",
    "    return padded\n",
    "\n",
    "def encode_docs_new_vocab(sp, max_length, docs):\n",
    "    \n",
    "    encoded =  [sp.EncodeAsIds(doc) for doc in docs]\n",
    "    padded = pad_sequences(encoded, maxlen = max_length, padding = 'post')\n",
    "    \n",
    "    return padded\n",
    "\n",
    "def f1(y_true, y_pred):    \n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "\n",
    "def generate_data(df, mean_length, ratio, token=None, sp=None):\n",
    "    \n",
    "    # split dataframe into singles dataframes for each rating score\n",
    "    data_1 =  df.loc[lambda df: df['review_rating'] == 1]\n",
    "    data_2 =  df.loc[lambda df: df['review_rating'] == 2]\n",
    "    data_3 =  df.loc[lambda df: df['review_rating'] == 3]\n",
    "    data_4 =  df.loc[lambda df: df['review_rating'] == 4]\n",
    "    data_5 =  df.loc[lambda df: df['review_rating'] == 5]\n",
    "    \n",
    "    # spliting each score dataframe into two dataframes set by a ratio\n",
    "    data_val_1 = data_1[:int(ratio*len(data_1))]\n",
    "    data_train_1 =  data_1[int(ratio*len(data_1)):]\n",
    "\n",
    "    data_val_2 = data_2[:int(ratio*len(data_2))]\n",
    "    data_train_2 =  data_2[int(ratio*len(data_2)):]\n",
    "\n",
    "    data_val_3 = data_3[:int(ratio*len(data_3))]\n",
    "    data_train_3 =  data_3[int(ratio*len(data_3)):]\n",
    "\n",
    "    data_val_4 = data_4[:int(ratio*len(data_4))]\n",
    "    data_train_4 =  data_4[int(ratio*len(data_4)):]\n",
    "\n",
    "    data_val_5 = data_5[:int(ratio*len(data_5))]\n",
    "    data_train_5 =  data_5[int(ratio*len(data_5)):]\n",
    "    \n",
    "    # concat dfs split by ratio\n",
    "    train_x = pd.concat([data_train_1, data_train_2,data_train_3,  data_train_4, data_train_5])\n",
    "    val_x = pd.concat([data_val_1, data_val_2,data_train_3, data_val_4, data_val_5])\n",
    "    \n",
    "    # setting positifs 1 for rating >3\n",
    "    train_x['score'] = train_x['review_rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "    val_x['score'] = val_x['review_rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "    \n",
    "    train_y = train_x['score'].values\n",
    "    val_y = val_x['score'].values\n",
    "    \n",
    "    #applying categorical from keras\n",
    "    y_train =  to_categorical(train_y)\n",
    "    y_val = to_categorical(val_y)\n",
    "    \n",
    "    # choosing tokenization by word or bpe\n",
    "    if sp == None:\n",
    "        X_train = encode_docs(token, mean_length, train_x['review_body'])\n",
    "        X_val = encode_docs(token, mean_length, val_x['review_body'])\n",
    "    else:\n",
    "        X_train = encode_docs_new_vocab(sp, mean_length, train_x['review_body'])\n",
    "        X_val = encode_docs_new_vocab(sp, mean_length, val_x['review_body'])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "def ml_model_score(vocab_size, input_length, dimension):\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, dimension, input_length=input_length)\n",
    "    sequence_input = Input(shape=(input_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=False))(embedded_sequences)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(64,  activation = 'relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    output_tensor = Dense(2, activation = 'softmax')(x)\n",
    "    \n",
    "    return Model(sequence_input, output_tensor)\n",
    "\n",
    "def ml_model_topics(vocab_size, input_length, dimension):\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, dimension, input_length=input_length)\n",
    "    sequence_input = Input(shape=(input_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=False))(embedded_sequences)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(64,  activation = 'relu')(x)\n",
    "\n",
    "    output_tensor = Dense(6, activation = 'sigmoid')(x)\n",
    "    \n",
    "    return Model(sequence_input, output_tensor)\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    _precision = true_pos / (predicted_pos + K.epsilon())\n",
    "    return _precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_pos = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_pos = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    _recall = true_pos / (possible_pos + K.epsilon())\n",
    "    return _recall\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Single prediction function</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import pickle, os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "import sentencepiece as spm\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# MACHINE_LEARNING = importlib.import_module('src.3_Prediction.ML.machine_learning')\n",
    "\n",
    "results = None\n",
    "PRED_Y = None\n",
    "TRUE_y = None\n",
    "\n",
    "def predict_reviews(review):\n",
    "    \n",
    "    config =  tf.compat.v1.ConfigProto() \n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "    #set_session( tf.compat.v1.Session(config=config))\n",
    "    tf.compat.v1.Session(config=config)\n",
    "\n",
    "    K.set_epsilon(1e-5)\n",
    "\n",
    "    # country, retailer = retailers['country'].values[0], retailers['name'].values[0].capitalize()\n",
    "    country = 'US'\n",
    "    lang = 'EN'\n",
    "    if country in ('FR', 'BE'):\n",
    "        lang = 'FR'\n",
    "    \n",
    "    # logger.log_message(\"PREDICTING SCORE FOR \" + country + '_' + retailer)\n",
    "    data = {'review_body': review, 'text_clean': review, 'title_clean': ''}\n",
    "    df = pnd.DataFrame([data])\n",
    "    #df = pd.read_csv('take.csv')\n",
    "    \n",
    "    df = df.dropna(subset=['review_body'])\n",
    "\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load('vocab.model')\n",
    "\n",
    "    input_length, vocab_size  = 256, 7500\n",
    "\n",
    "    model = ml_model_score(vocab_size, input_length, 100)\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy', f1])\n",
    "    model.load_weights('score.h5')\n",
    "\n",
    "    X = encode_docs_new_vocab(sp, input_length, df['review_body'])\n",
    "    # Y_true = df['review_rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "    Y = model.predict(X, batch_size=5000)\n",
    "    \n",
    "    # target_all = [1 if i > 0.5 else -1 for i in Y_true]\n",
    "    pred_all = [1 if i[0] < 0.5 else -1 for i in Y]\n",
    "\n",
    "\n",
    "    # pickle.dump(target_all, open('target_all.p', 'wb'))\n",
    "    pickle.dump(pred_all, open('pred_all.p', 'wb'))\n",
    "\n",
    "    _temp = pd.DataFrame(Y)\n",
    "    _temp['ml_score'] = _temp[0].apply(lambda x: 1 if x < 0.5 else -1)\n",
    "\n",
    "    df['ml_score'] = _temp['ml_score']\n",
    "    # df['ml_score']= df[['ml_score','review_rating']].apply(lambda x: x['ml_score'] if x['review_rating'] > 1 else -1, axis=1)\n",
    "\n",
    "    #logger.log_message(\"PREDICTING TOPIC FOR \" + country + '__' + retailer)\n",
    "\n",
    "    df['text_clean'] = df['text_clean'].replace(np.nan, '', regex=True)\n",
    "    df['title_clean'] = df['title_clean'].replace(np.nan, '', regex=True)\n",
    "\n",
    "    df['text'] = df['text_clean'] + ' ' + df['title_clean']\n",
    "    df['text'].fillna('', inplace=True)\n",
    "\n",
    "    model = ml_model_topics(vocab_size, input_length, 100)\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=['accuracy', f1])\n",
    "    model.load_weights('topics.h5')\n",
    "\n",
    "    X = encode_docs_new_vocab(sp, input_length, df['text'])\n",
    "    Y = model.predict(X, batch_size=5000)\n",
    "\n",
    "    targets = pickle.load(open('targets.p', 'rb'))\n",
    "    new_y = [[targets[index] if element > 0.95 else 0 for index, element in enumerate(elements)] for elements in Y]\n",
    "\n",
    "    _temp = pd.DataFrame(new_y)\n",
    "    df['ml_topic'] = list(_temp[[0,1,2,3,4,5]].values)\n",
    "\n",
    "    df['ml_topic'] = df['ml_topic'].apply(lambda x: [i for i in x if i != 0])\n",
    "\n",
    "    df.to_csv( 'result_ml.csv', index=False)\n",
    "    return df.iloc[0].to_dict(), review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "predict_reviews('fast shipped i love it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'>Multiple tests</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "reviews= ['absolutely love the taste amazing', \"got shipped in 2 days, nice\", 'fake coffe i would give it a 0 star', \"too expensive but still good taste\"]\n",
    "for review in reviews:\n",
    "  result = predict_reviews(review)\n",
    "  score = 'Avis positif'  if result[0]['ml_score'] ==1 else \"Avis NÃ©gatif\"\n",
    "  score_color = \"green\" if 'positif' in score else \"red\"\n",
    "  print ('\\nthe topic of the review: #' , result[1],'\\n\\n  is:  ', colored(result[0][\"ml_topic\"], \"red\"), 'and the predicted opinion is: ' ,colored(score, score_color), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
